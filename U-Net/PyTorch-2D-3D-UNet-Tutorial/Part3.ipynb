{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  Training with customdataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "import albumentations\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage.transform import resize\n",
    "from customdatasets import SegmentationDataSet1\n",
    "from transformations import (\n",
    "    ComposeDouble,\n",
    "    AlbuSeg2d,\n",
    "    FunctionWrapperDouble,\n",
    "    normalize_01,\n",
    "    create_dense_target,\n",
    ")\n",
    "from unet import UNet\n",
    "from trainer import Trainer\n",
    "\n",
    "\n",
    "# root directory\n",
    "root = pathlib.Path.cwd() / \"Carvana\"\n",
    "\n",
    "\n",
    "def get_filenames_of_path(path: pathlib.Path, ext: str = \"*\"):\n",
    "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
    "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
    "    return filenames\n",
    "\n",
    "\n",
    "# input and target files\n",
    "inputs = get_filenames_of_path(root / \"Input\")\n",
    "targets = get_filenames_of_path(root / \"Target\")\n",
    "\n",
    "# training transformations and augmentations\n",
    "transforms_training = ComposeDouble(\n",
    "    [\n",
    "        FunctionWrapperDouble(\n",
    "            resize, input=True, target=False, output_shape=(128, 128, 3)\n",
    "        ),\n",
    "        FunctionWrapperDouble(\n",
    "            resize,\n",
    "            input=False,\n",
    "            target=True,\n",
    "            output_shape=(128, 128),\n",
    "            order=0,\n",
    "            anti_aliasing=False,\n",
    "            preserve_range=True,\n",
    "        ),\n",
    "        AlbuSeg2d(albumentations.HorizontalFlip(p=0.5)),\n",
    "        FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "        FunctionWrapperDouble(\n",
    "            np.moveaxis, input=True, target=False, source=-1, destination=0\n",
    "        ),\n",
    "        FunctionWrapperDouble(normalize_01),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# validation transformations\n",
    "transforms_validation = ComposeDouble(\n",
    "    [\n",
    "        FunctionWrapperDouble(\n",
    "            resize, input=True, target=False, output_shape=(128, 128, 3)\n",
    "        ),\n",
    "        FunctionWrapperDouble(\n",
    "            resize,\n",
    "            input=False,\n",
    "            target=True,\n",
    "            output_shape=(128, 128),\n",
    "            order=0,\n",
    "            anti_aliasing=False,\n",
    "            preserve_range=True,\n",
    "        ),\n",
    "        FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "        FunctionWrapperDouble(\n",
    "            np.moveaxis, input=True, target=False, source=-1, destination=0\n",
    "        ),\n",
    "        FunctionWrapperDouble(normalize_01),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# random seed\n",
    "random_seed = 42\n",
    "\n",
    "# split dataset into training set and validation set\n",
    "train_size = 0.8  # 80:20 split\n",
    "\n",
    "inputs_train, inputs_valid = train_test_split(\n",
    "    inputs, random_state=random_seed, train_size=train_size, shuffle=True\n",
    ")\n",
    "\n",
    "targets_train, targets_valid = train_test_split(\n",
    "    targets, random_state=random_seed, train_size=train_size, shuffle=True\n",
    ")\n",
    "\n",
    "inputs_train, inputs_valid = inputs[:80], inputs[80:]\n",
    "targets_train, targets_valid = targets[:80], targets[:80]\n",
    "\n",
    "# dataset training\n",
    "dataset_train = SegmentationDataSet1(\n",
    "    inputs=inputs_train, targets=targets_train, transform=transforms_training\n",
    ")\n",
    "\n",
    "# dataset validation\n",
    "dataset_valid = SegmentationDataSet1(\n",
    "    inputs=inputs_valid, targets=targets_valid, transform=transforms_validation\n",
    ")\n",
    "\n",
    "# dataloader training\n",
    "dataloader_training = DataLoader(dataset=dataset_train, batch_size=2, shuffle=True)\n",
    "\n",
    "# dataloader validation\n",
    "dataloader_validation = DataLoader(dataset=dataset_valid, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DatasetViewer instances\n",
    "from visual import DatasetViewer\n",
    "\n",
    "dataset_viewer_training = DatasetViewer(dataset_train)\n",
    "dataset_viewer_validation = DatasetViewer(dataset_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad66bb36bd144abfafc37dc2e55bf85d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# model\n",
    "model = UNet(\n",
    "    in_channels=3,\n",
    "    out_channels=2,\n",
    "    n_blocks=4,\n",
    "    start_filters=32,\n",
    "    activation=\"relu\",\n",
    "    normalization=\"batch\",\n",
    "    conv_mode=\"same\",\n",
    "    dim=2,\n",
    ").to(device)\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    training_dataloader=dataloader_training,\n",
    "    validation_dataloader=dataloader_validation,\n",
    "    lr_scheduler=None,\n",
    "    epochs=2,\n",
    "    epoch=0,\n",
    "    notebook=True,\n",
    ")\n",
    "\n",
    "# start training\n",
    "training_losses, validation_losses, lr_rates = trainer.run_trainer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with customdataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945290fece374097a4dc45d33b0c7e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Caching:   0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399923dfa1dd43bcae82a78dc343db80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Caching:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import pathlib\n",
    "from transformations import (\n",
    "    ComposeDouble,\n",
    "    normalize_01,\n",
    "    AlbuSeg2d,\n",
    "    FunctionWrapperDouble,\n",
    "    create_dense_target,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from customdatasets import SegmentationDataSet2\n",
    "import torch\n",
    "import numpy as np\n",
    "from unet import UNet\n",
    "from trainer import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage.transform import resize\n",
    "import albumentations\n",
    "\n",
    "# root directory\n",
    "root = pathlib.Path.cwd() / \"Carvana\"\n",
    "\n",
    "\n",
    "def get_filenames_of_path(path: pathlib.Path, ext: str = \"*\"):\n",
    "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
    "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
    "    return filenames\n",
    "\n",
    "\n",
    "# input and target files\n",
    "inputs = get_filenames_of_path(root / \"Input\")\n",
    "targets = get_filenames_of_path(root / \"Target\")\n",
    "\n",
    "# pre-transformations\n",
    "pre_transforms = ComposeDouble(\n",
    "    [\n",
    "        FunctionWrapperDouble(\n",
    "            resize, input=True, target=False, output_shape=(128, 128, 3)\n",
    "        ),\n",
    "        FunctionWrapperDouble(\n",
    "            resize,\n",
    "            input=False,\n",
    "            target=True,\n",
    "            output_shape=(128, 128),\n",
    "            order=0,\n",
    "            anti_aliasing=False,\n",
    "            preserve_range=True,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# training transformations and augmentations\n",
    "transforms_training = ComposeDouble(\n",
    "    [\n",
    "        AlbuSeg2d(albumentations.HorizontalFlip(p=0.5)),\n",
    "        FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "        FunctionWrapperDouble(\n",
    "            np.moveaxis, input=True, target=False, source=-1, destination=0\n",
    "        ),\n",
    "        FunctionWrapperDouble(normalize_01),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# validation transformations\n",
    "transforms_validation = ComposeDouble(\n",
    "    [\n",
    "        FunctionWrapperDouble(\n",
    "            resize, input=True, target=False, output_shape=(128, 128, 3)\n",
    "        ),\n",
    "        FunctionWrapperDouble(\n",
    "            resize,\n",
    "            input=False,\n",
    "            target=True,\n",
    "            output_shape=(128, 128),\n",
    "            order=0,\n",
    "            anti_aliasing=False,\n",
    "            preserve_range=True,\n",
    "        ),\n",
    "        FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "        FunctionWrapperDouble(\n",
    "            np.moveaxis, input=True, target=False, source=-1, destination=0\n",
    "        ),\n",
    "        FunctionWrapperDouble(normalize_01),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# random seed\n",
    "random_seed = 42\n",
    "\n",
    "# split dataset into training set and validation set\n",
    "train_size = 0.8  # 80:20 split\n",
    "\n",
    "inputs_train, inputs_valid = train_test_split(\n",
    "    inputs, random_state=random_seed, train_size=train_size, shuffle=True\n",
    ")\n",
    "\n",
    "targets_train, targets_valid = train_test_split(\n",
    "    targets, random_state=random_seed, train_size=train_size, shuffle=True\n",
    ")\n",
    "\n",
    "# inputs_train, inputs_valid = inputs[:80], inputs[80:]\n",
    "# targets_train, targets_valid = targets[:80], targets[:80]\n",
    "\n",
    "# dataset training\n",
    "dataset_train = SegmentationDataSet2(\n",
    "    inputs=inputs_train,\n",
    "    targets=targets_train,\n",
    "    transform=transforms_training,\n",
    "    use_cache=True,\n",
    "    pre_transform=pre_transforms,\n",
    ")\n",
    "\n",
    "# dataset validation\n",
    "dataset_valid = SegmentationDataSet2(\n",
    "    inputs=inputs_valid,\n",
    "    targets=targets_valid,\n",
    "    transform=transforms_validation,\n",
    "    use_cache=True,\n",
    "    pre_transform=pre_transforms,\n",
    ")\n",
    "\n",
    "# dataloader training\n",
    "dataloader_training = DataLoader(dataset=dataset_train, batch_size=2, shuffle=True)\n",
    "\n",
    "# dataloader validation\n",
    "dataloader_validation = DataLoader(dataset=dataset_valid, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DatasetViewer instances\n",
    "from visual import DatasetViewer\n",
    "\n",
    "dataset_viewer_training = DatasetViewer(dataset_train)\n",
    "dataset_viewer_validation = DatasetViewer(dataset_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Could not load the Qt platform plugin \"xcb\" in \"\" even though it was found.\n"
     ]
    }
   ],
   "source": [
    "# open napari instance for training dataset\n",
    "# navigate with 'n' for next and 'b' for back on the keyboard\n",
    "dataset_viewer_training.napari()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open napari instance for validation dataset\n",
    "# navigate with 'n' for next and 'b' for back on the keyboard\n",
    "dataset_viewer_validation.napari()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/annaluru/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:143: UserWarning: \n",
      "NVIDIA RTX A4000 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA RTX A4000 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a3b20dcde26d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m model = UNet(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    895\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    896\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# model\n",
    "model = UNet(\n",
    "    in_channels=3,\n",
    "    out_channels=2,\n",
    "    n_blocks=4,\n",
    "    start_filters=32,\n",
    "    activation=\"relu\",\n",
    "    normalization=\"batch\",\n",
    "    conv_mode=\"same\",\n",
    "    dim=2,\n",
    ").to(device)\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    training_dataloader=dataloader_training,\n",
    "    validation_dataloader=dataloader_validation,\n",
    "    lr_scheduler=None,\n",
    "    epochs=10,\n",
    "    epoch=0,\n",
    "    notebook=True,\n",
    ")\n",
    "\n",
    "# start training\n",
    "training_losses, validation_losses, lr_rates = trainer.run_trainer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with customdataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pathlib\n",
    "from transformations import (\n",
    "    ComposeDouble,\n",
    "    normalize_01,\n",
    "    AlbuSeg2d,\n",
    "    FunctionWrapperDouble,\n",
    "    create_dense_target,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from customdatasets import SegmentationDataSet3\n",
    "import torch\n",
    "import numpy as np\n",
    "from unet import UNet\n",
    "from trainer import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage.transform import resize\n",
    "import albumentations\n",
    "\n",
    "# root directory\n",
    "root = pathlib.Path.cwd() / \"Carvana\"\n",
    "\n",
    "\n",
    "def get_filenames_of_path(path: pathlib.Path, ext: str = \"*\"):\n",
    "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
    "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
    "    return filenames\n",
    "\n",
    "\n",
    "# input and target files\n",
    "inputs = get_filenames_of_path(root / \"Input\")\n",
    "targets = get_filenames_of_path(root / \"Target\")\n",
    "\n",
    "# pre-transformations\n",
    "pre_transforms = ComposeDouble(\n",
    "    [\n",
    "        FunctionWrapperDouble(\n",
    "            resize, input=True, target=False, output_shape=(128, 128, 3)\n",
    "        ),\n",
    "        FunctionWrapperDouble(\n",
    "            resize,\n",
    "            input=False,\n",
    "            target=True,\n",
    "            output_shape=(128, 128),\n",
    "            order=0,\n",
    "            anti_aliasing=False,\n",
    "            preserve_range=True,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# training transformations and augmentations\n",
    "transforms_training = ComposeDouble(\n",
    "    [\n",
    "        AlbuSeg2d(albumentations.HorizontalFlip(p=0.5)),\n",
    "        FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "        FunctionWrapperDouble(\n",
    "            np.moveaxis, input=True, target=False, source=-1, destination=0\n",
    "        ),\n",
    "        FunctionWrapperDouble(normalize_01),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# validation transformations\n",
    "transforms_validation = ComposeDouble(\n",
    "    [\n",
    "        FunctionWrapperDouble(\n",
    "            resize, input=True, target=False, output_shape=(128, 128, 3)\n",
    "        ),\n",
    "        FunctionWrapperDouble(\n",
    "            resize,\n",
    "            input=False,\n",
    "            target=True,\n",
    "            output_shape=(128, 128),\n",
    "            order=0,\n",
    "            anti_aliasing=False,\n",
    "            preserve_range=True,\n",
    "        ),\n",
    "        FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "        FunctionWrapperDouble(\n",
    "            np.moveaxis, input=True, target=False, source=-1, destination=0\n",
    "        ),\n",
    "        FunctionWrapperDouble(normalize_01),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# random seed\n",
    "random_seed = 42\n",
    "\n",
    "# split dataset into training set and validation set\n",
    "train_size = 0.8  # 80:20 split\n",
    "\n",
    "inputs_train, inputs_valid = train_test_split(\n",
    "    inputs, random_state=random_seed, train_size=train_size, shuffle=True\n",
    ")\n",
    "\n",
    "targets_train, targets_valid = train_test_split(\n",
    "    targets, random_state=random_seed, train_size=train_size, shuffle=True\n",
    ")\n",
    "\n",
    "# inputs_train, inputs_valid = inputs[:80], inputs[80:]\n",
    "# targets_train, targets_valid = targets[:80], targets[:80]\n",
    "\n",
    "# dataset training\n",
    "dataset_train = SegmentationDataSet3(\n",
    "    inputs=inputs_train,\n",
    "    targets=targets_train,\n",
    "    transform=transforms_training,\n",
    "    use_cache=True,\n",
    "    pre_transform=pre_transforms,\n",
    ")\n",
    "\n",
    "# dataset validation\n",
    "dataset_valid = SegmentationDataSet3(\n",
    "    inputs=inputs_valid,\n",
    "    targets=targets_valid,\n",
    "    transform=transforms_validation,\n",
    "    use_cache=True,\n",
    "    pre_transform=pre_transforms,\n",
    ")\n",
    "\n",
    "# dataloader training\n",
    "dataloader_training = DataLoader(dataset=dataset_train, batch_size=2, shuffle=True)\n",
    "\n",
    "# dataloader validation\n",
    "dataloader_validation = DataLoader(dataset=dataset_valid, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# model\n",
    "model = UNet(\n",
    "    in_channels=3,\n",
    "    out_channels=2,\n",
    "    n_blocks=4,\n",
    "    start_filters=32,\n",
    "    activation=\"relu\",\n",
    "    normalization=\"batch\",\n",
    "    conv_mode=\"same\",\n",
    "    dim=2,\n",
    ").to(device)\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    training_dataloader=dataloader_training,\n",
    "    validation_dataloader=dataloader_validation,\n",
    "    lr_scheduler=None,\n",
    "    epochs=10,\n",
    "    epoch=0,\n",
    "    notebook=True,\n",
    ")\n",
    "\n",
    "# start training\n",
    "training_losses, validation_losses, lr_rates = trainer.run_trainer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_name = \"carvana_model.pt\"\n",
    "torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# model\n",
    "model = UNet(\n",
    "    in_channels=3,\n",
    "    out_channels=2,\n",
    "    n_blocks=4,\n",
    "    start_filters=32,\n",
    "    activation=\"relu\",\n",
    "    normalization=\"batch\",\n",
    "    conv_mode=\"same\",\n",
    "    dim=2,\n",
    ").to(device)\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr_rate_finder import LearningRateFinder\n",
    "\n",
    "lrf = LearningRateFinder(model, criterion, optimizer, device)\n",
    "lrf.fit(dataloader_training, steps=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual import plot_training\n",
    "\n",
    "fig = plot_training(\n",
    "    training_losses,\n",
    "    validation_losses,\n",
    "    lr_rates,\n",
    "    gaussian=True,\n",
    "    sigma=1,\n",
    "    figsize=(10, 4),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
